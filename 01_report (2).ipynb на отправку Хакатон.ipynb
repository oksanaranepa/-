{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d68b55-9361-46e4-84f1-2b1dcea7813f",
   "metadata": {},
   "source": [
    "# Аналитический отчёт по задаче прогнозирования целевого действия\n",
    "\n",
    "**Цель проекта:**  \n",
    "Построить модель машинного обучения, прогнозирующую вероятность совершения целевого действия пользователем в рамках сессии на сайте.\n",
    "\n",
    "**Данные:**  \n",
    "- `ga_sessions.pkl` — данные о визитах пользователей  \n",
    "- `ga_hits.csv` — данные о событиях внутри визитов (агрегированы до уровня сессии)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5fe95",
   "metadata": {},
   "source": [
    "Комментарий: \n",
    "Этот код выполняет загрузку двух наборов данных для последующего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b89411",
   "metadata": {},
   "source": [
    "Загрузка данных сессий (sessions) из pickle-формата - бинарного формата хранения объектов Python\n",
    "\n",
    "Загрузка агрегированных данных о взаимодействиях (hits_agg) из Parquet-формата - колоночного формата, оптимизированного для аналитических запросов\n",
    "\n",
    "Вывод размерности каждого датафрейма, что помогает оценить объем данных перед их обработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d872948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Читаю данные...\")\n",
    "# Загрузка данных сессий из pickle файла\n",
    "sessions = pd.read_pickle(\"../ga_sessions.pkl\")\n",
    "# Загрузка агрегированных данных хитов из parquet файла\n",
    "hits_agg = pd.read_parquet(\"../hits_agg.parquet\")\n",
    "\n",
    "# Вывод размерности (количество строк и столбцов) каждого датафрейма\n",
    "print(\"Размер sessions:\", sessions.shape)  # Формат: (количество_строк, количество_столбцов)\n",
    "print(\"Размер hits_agg:\", hits_agg.shape)  # Формат: (количество_строк, количество_столбцов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bfcc25",
   "metadata": {},
   "source": [
    "Комментарий: Этот этап включает объединение данных и предобработку целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9b259",
   "metadata": {},
   "source": [
    "Если доля target=1 очень мала (<5%), это задача с несбалансированными классами\n",
    "\n",
    "Если доля около 50%, данные хорошо сбалансированы\n",
    "\n",
    "Значение помогает выбрать стратегию построения модели и её оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Объединяю данные...\")\n",
    "# Объединение таблиц sessions и hits_agg по ключевому полю session_id\n",
    "# how=\"left\" означает левое соединение: все строки из sessions сохраняются, \n",
    "# а данные из hits_agg добавляются по совпадению session_id\n",
    "df = sessions.merge(hits_agg, on=\"session_id\", how=\"left\")\n",
    "\n",
    "print(\"Пропуски до заполнения:\")\n",
    "# Проверка количества пропущенных значений в ключевых столбцах\n",
    "# Пропуски возникают из-за left join, если в hits_agg нет записи с соответствующим session_id\n",
    "print(df[[\"hits_cnt\",\"pages_nunique\",\"actions_nunique\",\"categories_nunique\",\"target\"]].isna().sum())\n",
    "\n",
    "# Заполнение пропусков нулями для ключевых столбцов\n",
    "for col in [\"hits_cnt\", \"pages_nunique\", \"actions_nunique\", \"categories_nunique\", \"target\"]:\n",
    "    df[col] = df[col].fillna(0)  # Заменяем NaN на 0 для указанных столбцов\n",
    "\n",
    "# Преобразование столбца target к целочисленному типу\n",
    "# Это важно, так как target обычно используется как бинарная метка (0/1)\n",
    "df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "print(\"Пропуски после заполнения:\")\n",
    "# Проверка, что все пропуски устранены\n",
    "print(df[[\"hits_cnt\",\"pages_nunique\",\"actions_nunique\",\"categories_nunique\",\"target\"]].isna().sum())\n",
    "\n",
    "print(\"\\nРазмер итогового датафрейма:\", df.shape)  # Вывод финальной размерности данных\n",
    "print(\"Доля target=1:\", df[\"target\"].mean())  # Расчет баланса классов - важный показатель для задач классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905643a6",
   "metadata": {},
   "source": [
    "Комментарий:Этот код визуализирует распределение целевой переменной, что является важным этапом EDA (Exploratory Data Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Создание столбчатой диаграммы распределения значений target\n",
    "# value_counts(normalize=True) возвращает относительные частоты (доли) вместо абсолютных количеств\n",
    "df[\"target\"].value_counts(normalize=True).plot(kind=\"bar\")\n",
    "plt.title(\"Распределение целевого признака\")  # Заголовок графика\n",
    "plt.ylabel(\"Доля сессий\")  # Подпись оси Y - доля/процент сессий\n",
    "plt.xlabel(\"Target\")  # Подпись оси X - значения целевой переменной\n",
    "plt.show()  # Отображение графика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee6277-7071-4a63-b635-5b4ba64afacc",
   "metadata": {},
   "source": [
    "**Комментарий:**  \n",
    "Большинство сессий содержит целевое действие. Это связано с широким определением таргета, включающим события типа `sub_*` и `start_chat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение boxplot (ящика с усами) для сравнения распределения hits_cnt по группам target\n",
    "df.boxplot(column=\"hits_cnt\", by=\"target\")\n",
    "plt.title(\"Количество событий в сессии по таргету\")  # Основной заголовок графика\n",
    "plt.suptitle(\"\")  # Удаление автоматического заголовка, который добавляет pandas\n",
    "plt.xlabel(\"Target\")  # Подпись оси X - значения целевой переменной (0 или 1)\n",
    "plt.ylabel(\"hits_cnt\")  # Подпись оси Y - количество событий в сессии\n",
    "plt.show()  # Отображение графика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69208620-10f1-4728-9e9f-c0576e6fc8b7",
   "metadata": {},
   "source": [
    "**Комментарий:**  \n",
    "Сессии с целевым действием характеризуются большим количеством событий. Это подтверждает гипотезу о том, что вовлечённость пользователя напрямую связана с вероятностью совершения целевого действия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fae2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группировка данных по категории устройства и расчет среднего значения target для каждой группы\n",
    "df.groupby(\"device_category\")[\"target\"].mean().plot(kind=\"bar\")\n",
    "plt.title(\"Доля целевых сессий по типу устройства\")  # Заголовок: показывает, что анализируем конверсию по устройствам\n",
    "plt.ylabel(\"Среднее значение target\")  # Ось Y: фактически это доля сессий с target=1 (конверсионная доля)\n",
    "plt.xlabel(\"Тип устройства\")  # Ось X: категории устройств (mobile, desktop, tablet и т.д.)\n",
    "plt.show()  # Отображение графика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29167238-d592-4fd0-b7c4-662433a827c5",
   "metadata": {},
   "source": [
    "**Комментарий:**  \n",
    "Наблюдаются различия в доле целевых сессий между типами устройств, что указывает на влияние устройства пользователя на поведение и конверсию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39c7c5-5b14-4087-9b6f-84aee2b6b7ea",
   "metadata": {},
   "source": [
    "## Подход к машинному обучению\n",
    "\n",
    "В качестве baseline была использована логистическая регрессия как простая и интерпретируемая модель.  \n",
    "Далее была обучена модель машинного обучения на деревьях решений (RandomForest),\n",
    "позволяющая учитывать нелинейные зависимости и взаимодействия признаков.\n",
    "\n",
    "Качество моделей оценивалось по метрике ROC-AUC на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Определение признаков:\n",
    "# Числовые признаки (метрики и счетчики)\n",
    "num_features = [\n",
    "    \"visit_number\",       # Номер визита пользователя\n",
    "    \"hits_cnt\",           # Количество событий в сессии\n",
    "    \"pages_nunique\",      # Количество уникальных страниц\n",
    "    \"actions_nunique\",    # Количество уникальных действий\n",
    "    \"categories_nunique\"  # Количество уникальных категорий\n",
    "]\n",
    "\n",
    "# Категориальные признаки (дискретные переменные)\n",
    "cat_features = [\"device_category\"]  # Тип устройства\n",
    "\n",
    "# Подготовка матрицы признаков и целевой переменной\n",
    "X = df[num_features + cat_features]  # Объединение всех признаков\n",
    "y = df[\"target\"]  # Целевая переменная\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "# test_size=0.2: 20% данных для тестирования, 80% для обучения\n",
    "# random_state=42: фиксация случайного состояния для воспроизводимости\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Создание трансформера для предобработки признаков\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # OneHotEncoder для категориальных признаков\n",
    "        # handle_unknown=\"ignore\": игнорировать новые категории в тестовых данных\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "        # \"passthrough\": числовые признаки используются без изменений\n",
    "        (\"num\", \"passthrough\", num_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Создание pipeline: цепочка преобразований и модель\n",
    "logreg = Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", preprocess),  # Шаг предобработки\n",
    "        # Логистическая регрессия с увеличенным числом итераций\n",
    "        (\"clf\", LogisticRegression(max_iter=200))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Получение вероятностей для положительного класса на тестовых данных\n",
    "# predict_proba возвращает вероятности для обоих классов, берем только для класса 1\n",
    "proba_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Расчет ROC-AUC метрики\n",
    "# ROC-AUC оценивает способность модели различать классы\n",
    "auc_lr = roc_auc_score(y_test, proba_lr)\n",
    "\n",
    "print(\"Logistic Regression ROC-AUC:\", auc_lr)  # Вывод результата"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af2c0b-2c3b-447a-9a74-92de60b0b2d6",
   "metadata": {},
   "source": [
    "Логистическая регрессия используется как baseline-модель. \n",
    "Она демонстрирует хорошее качество, однако ограничена линейной\n",
    "формой зависимости между признаками и целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Создание подвыборки для обучения (300K строк вместо всего датасета)\n",
    "# Используется из-за ограничений оперативной памяти (8 ГБ ОЗУ)\n",
    "# random_state=42 обеспечивает воспроизводимость случайной выборки\n",
    "df_sample = df.sample(300_000, random_state=42)\n",
    "\n",
    "# Подготовка признаков и целевой переменной для подвыборки\n",
    "# ВАЖНО: используем только числовые признаки, категориальные исключены\n",
    "X = df_sample[num_features]\n",
    "y = df_sample[\"target\"]\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки с учетом баланса классов\n",
    "# stratify=y гарантирует сохранение пропорции классов в разделенных выборках\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Создание модели RandomForest с заданными гиперпараметрами\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,      # Количество деревьев в ансамбле\n",
    "    max_depth=12,          # Максимальная глубина каждого дерева (ограничение для борьбы с переобучением)\n",
    "    n_jobs=-1,             # Использование всех ядер процессора для параллельных вычислений\n",
    "    random_state=42        # Фиксация случайности для воспроизводимости\n",
    ")\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Получение вероятностей принадлежности к классу 1 для тестовой выборки\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Расчет ROC-AUC метрики для оценки качества модели\n",
    "auc_rf = roc_auc_score(y_test, proba_rf)\n",
    "\n",
    "print(\"RandomForest ROC-AUC:\", auc_rf)  # Вывод результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cab423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создание DataFrame для сравнения результатов моделей\n",
    "results = pd.DataFrame({\n",
    "    \"Модель\": [\"Logistic Regression\", \"RandomForest\"],  # Названия тестируемых моделей\n",
    "    \"ROC-AUC\": [auc_lr, auc_rf]  # Значения ROC-AUC метрики для каждой модели\n",
    "})\n",
    "\n",
    "results  # Отображение таблицы с результатами (в Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d4ade-56df-4a18-b44f-87ba2c36c579",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "- Данные по событиям (`ga_hits`) были агрегированы до уровня сессии и объединены с таблицей визитов (`ga_sessions`).\n",
    "- Проведён EDA: исследовано распределение таргета и связь целевого действия с поведенческими признаками.\n",
    "- В качестве baseline обучена Logistic Regression; далее обучена ML-модель RandomForest на деревьях решений.\n",
    "- RandomForest показал более высокое качество по ROC-AUC по сравнению с baseline, что объясняется способностью деревьев учитывать нелинейные зависимости и пороговые эффекты.\n",
    "- Наибольший вклад в прогноз вносят признаки активности пользователя в сессии (количество событий, разнообразие действий и страниц)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
